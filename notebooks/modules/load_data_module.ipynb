{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b9ea0-69c7-434b-af5e-a084a57999aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "import ast\n",
    "import copy\n",
    "import glob\n",
    "import advertools as adv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 285\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from spacymoji import Emoji\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "from textblob import Word\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d023b88-3c3b-46df-a3d4-03fa2b149d81",
   "metadata": {},
   "source": [
    "# Load data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7506e-accd-4311-bf0a-cf788c426c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(paths, dtype):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        global paths to csv files\n",
    "    output:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "             \n",
    "    return pd.concat([pd.read_csv(path, dtype=dtype) for path in sorted(paths)], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab21b1-7e18-4433-8139-6e2e10273940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_feather(paths):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        global paths to feather files\n",
    "    output:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    return pd.concat([pd.read_feather(path) for path in sorted(paths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683aa03-db5d-4789-951f-411e4ad74928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, chunk_size = 10000): \n",
    "    list_of_chunks = []\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        list_of_chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return list_of_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25aeed2-d564-45ea-b63f-4fb7f35f5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_between(df, start, end):\n",
    "    \"\"\"\n",
    "    *** \n",
    "    input:\n",
    "        df: dataframe of tweets/replies/quotes\n",
    "        start: starting day : data frame, filter rows by column used_at_time value\n",
    "    \"\"\"\n",
    "    \n",
    "    df['date'] = df['created_at'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "\n",
    "    if start < end:\n",
    "        return df.loc[(df['date'] < end) & (df['date'] > start)]\n",
    "    else:\n",
    "        return df.loc[(df['date'] < end) | (df['date'] > start)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008f2e9-ecd0-4b6a-ac8a-325f838680fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_df(paths, pct, dtype):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        paths = global paths to csv files\n",
    "        pct = percentage of dataframe\n",
    "    output:\n",
    "        sample dataframe, for each csv file it takes pct% of the rows\n",
    "    \"\"\"\n",
    "    sample_df_list = []\n",
    "    for path in paths:\n",
    "        sample_df_list.append(pd.read_csv(path, dtype=dtype).sample(frac = pct))\n",
    "        \n",
    "    return pd.concat(sample_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2da38-c9ca-4dc8-92d6-8d221cf32ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_reply_quote(sample_df, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        sample_df: sample_tweet\n",
    "        df_conversation: replies or quotes dataframe\n",
    "    output:\n",
    "        dataframe, replies or quotes of the sample tweets\n",
    "    \"\"\"\n",
    "    conversation_list = []\n",
    "    print(len(sample_df))\n",
    "    for cnt, conv_id in enumerate(sample_df['conversation_id']):\n",
    "        conversation_list.append(get_conversation(conv_id, df_conversation))\n",
    "        if cnt % 1000 == 0:\n",
    "            print(cnt/len(sample_df))\n",
    "\n",
    "    return pd.concat(conversation_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f6eea-d1ee-49f3-83b2-b72b09e79512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_users(df_input):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_input: dataframe storing users information\n",
    "    output:\n",
    "        dataframe with not duplicates for user, ie. only has one row per users\n",
    "    \"\"\"          \n",
    "    return df_input.drop_duplicates(subset=\"id\", keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a7240-f381-4926-874e-1f6db7b68f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(cid, df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        cid: conversation id\n",
    "    output:\n",
    "        subdataframe, containing conversation of the specific tweet\n",
    "    \"\"\"\n",
    "\n",
    "    return df.loc[df['reference_tweet_id'] == cid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73428ae7-abbc-4b49-9787-2b68071a25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(ref_id, df_tweets):\n",
    "    dtemp = df_tweets.loc[df_tweets['conversation_id']==ref_id]\n",
    "    if len(dtemp) == 1:\n",
    "        return dtemp.iloc[0]['clean_text']\n",
    "    else:\n",
    "        []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952c41e-50e5-48c9-b300-8eea0602bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_unknown_users_from_tweets(df_tweets, df_clean_users):\n",
    "#     \"\"\"\n",
    "#     input:\n",
    "#         df_tweets: dataframe of tweets\n",
    "#         df_clean_users: dataframe of clean users,i.e, dataframe of users, each user one row.\n",
    "#     output:\n",
    "#         dataframe of tweets, the tweets with no author ID has been removed.\n",
    "#     \"\"\"\n",
    "#     unwanted_author_ids = []\n",
    "#     for author_id in df_tweets['author_id'].unique():\n",
    "#         if len(df_clean_users.loc[df_clean_users['id']==author_id]) == 0:\n",
    "#             unwanted_author_ids.append(df_tweets.loc[df_tweets['author_id']==author_id].index)\n",
    "#     flatten_ids = [item for sublist in unwanted_author_ids for item in sublist]        \n",
    "#     return df_tweets.drop(flatten_ids)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68a28c-5648-414f-8e73-639b0a7a3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_unknown_users_conversation(df_tweets, df_conversation, df_users):\n",
    "#     \"\"\"\n",
    "#     input:\n",
    "#         df_tweets = loaded tweets, containing tweets of unknown users\n",
    "#         df_users =  dataframe, containting users informations\n",
    "#         df_conversation: dataframe of replies or quotes that contains replies/quotes to unknown user\n",
    "#     output:\n",
    "#         clean conversation dataframe, i.e replies and quotes of a tweet with known author\n",
    "#     \"\"\"\n",
    "#     unknown_users = list(set(df_tweets['author_id'].unique()) - set(df_users['id'].unique()))\n",
    "#     unvanted_idx = []\n",
    "#     for user_id in unknown_users:\n",
    "#          unvanted_idx.append(df_tweets.loc[df_tweets['author_id']==user_id].index)\n",
    "#         for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f374206-52e4-4e22-a47b-967068dfb7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d87b2e-78c6-413a-9b33-3333a5af616f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d470ec-22ec-496b-8b33-650914d3f227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7f8e0-92a7-4f28-b63e-e9d394a76da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677656c-3eaa-49ba-a36e-415c6ada3e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02c4b1-95ce-4bd8-b7ba-a434dac3fb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcef7f7-3118-4827-87b7-df953c37a37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82bef0-bae0-4149-bc03-8521d2cf2c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4466ef8-99b2-4857-b56c-9bd1bc860aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1355cd-2866-43d0-a902-04698bcc0bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff981920-d5d6-4637-8045-b873086583b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35cb9a-f315-410c-9605-7ecedc14738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f8888-f917-4804-8efe-bcfbcabeae5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2108c-f78b-47d1-9ae3-43b14d9dae1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9805e6-a67e-4833-8ef3-76668d399597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73996b8b-e706-4a9e-8ca5-b4e41038fcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2223cce-b28c-4add-bb66-8065437645f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fd11d-61cb-41e0-9631-acb4dc7cba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_polarity(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text_string\n",
    "    output:\n",
    "        semantic_score\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text_string)\n",
    "    score = blob.polarity\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score == 0:\n",
    "        return 'neutral'\n",
    "    elif score < 0:\n",
    "        return 'negative'\n",
    "    \n",
    "    \n",
    "get_semantic_polarity('This is What I try here, amazingly boring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c74990-23c4-4152-9304-04445fb8262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c61cb-91e6-4c42-905a-4a7d4c4a9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_conversation(cid, df):\n",
    "    all_replies =  df.loc[df['conversation_id'] == cid]\n",
    "    return all_replies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc8065-8af3-4cbe-9fd6-e9c6f1d87ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: you may need to delete this function\n",
    "def get_replies_referenced_tweet_id(input_string):\n",
    "    return int(ast.literal_eval(input_string)[0]['id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0131df3-7b23-4710-ba27-3464e81679d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e889a-10e8-4506-9121-7e24e8915b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e43343-9d02-4cf6-a43f-4a37b5089c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbc58b-5b93-49f7-bc51-925f32e26979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74997fa1-16e8-4262-b211-ebb0ac9510e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8976ff-975a-4848-9395-d312a9514644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_reply_like_quote_retweet(df_row):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_row: a row from tweets dataframe\n",
    "    output:\n",
    "        integer, \n",
    "    \"\"\"\n",
    "    return int(df_row.retweet_count) + int(df_row.like_count) + int(df_row.quote_count) + int(df_row.reply_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c80c64-028a-4453-9910-a30d36a0ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polarity(df):\n",
    "    try:\n",
    "        return df['clean_text'].apply(lambda x: get_semantic_polarity(x))\n",
    "    except:\n",
    "        return print('Error: Column \"clean_text\" does not exist')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18665ecc-6d92-4d40-aa72-e4d4e2047fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_reaction(df):\n",
    "    try:\n",
    "        return df.apply(lambda x: x.like_count + x.quote_count + x.retweet_count + x.all_reply_count, axis=1)\n",
    "    except: print('Error: Column \"all_reply_count\" does not exist')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b5cc8-23b1-4c06-828f-99d3c1eb6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emoji_group(df):\n",
    "    return df['text'].apply(lambda x: extract_emoji_group(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1834a2-02c7-4f58-ba9c-fb29e11c1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_all_reply(df, df_replies):\n",
    "    return df['conversation_id'].apply(lambda x: len(get_all_reply(x, df_replies)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
