{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b9ea0-69c7-434b-af5e-a084a57999aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "import ast\n",
    "import copy\n",
    "import glob\n",
    "import advertools as adv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 285\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "from spacymoji import Emoji\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "from textblob import Word\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d023b88-3c3b-46df-a3d4-03fa2b149d81",
   "metadata": {},
   "source": [
    "# Load data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7506e-accd-4311-bf0a-cf788c426c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(paths):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        global paths to csv files\n",
    "    output:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for path in paths:\n",
    "        df_list.append(pd.read_csv(path))\n",
    "             \n",
    "    return pd.concat(df_list, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b90ea-adea-4d27-9b63-c30ae260c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check what it returns again\n",
    "\n",
    "def get_missing_replies(df_tweets, df_replies):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_tweets: dataframe of all tweets\n",
    "        df_replies: dataframe of all replies\n",
    "    output:\n",
    "        returns the list of conversations with missing replies.\n",
    "    \"\"\"\n",
    "    tweets_with_reply = df_tweets.loc[df_tweets['reply_count']>0]\n",
    "    \n",
    "    all_tweets_conversation_ids = tweets_with_reply['conversation_id'].unique().tolist()\n",
    "    all_replies_conversation_ids = df_replies['conversation_id'].unique().tolist()\n",
    "    \n",
    "    return list(set(all_tweets_conversation_ids) - set(all_replies_conversation_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156bf2e-877f-48c4-b2fc-8722754d3276",
   "metadata": {},
   "source": [
    "# Data cleaning / Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68a28c-5648-414f-8e73-639b0a7a3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        string\n",
    "    output: \n",
    "        urls list\n",
    "    \"\"\"\n",
    "\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text_string)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "\n",
    "extract_urls(\"this suppose to extract urls like https://www.bbc.com/travel/article/20220814-the-floating-homes-of-lake-titicaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f374206-52e4-4e22-a47b-967068dfb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_urls_removed(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        string\n",
    "    output: \n",
    "        text_string urls removed\n",
    "    \"\"\"\n",
    "        \n",
    "    return re.sub(r'http\\S+', '', text_string)\n",
    "\n",
    "\n",
    "tweet_urls_removed(\"this suppose to extract urls like https://www.bbc.com/travel/article/20220814-the-floating-homes-of-lake-titicaca and retrun the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d87b2e-78c6-413a-9b33-3333a5af616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of hastags found in input text\n",
    "    \"\"\"\n",
    "    hastags = \"#(\\w+)\"\n",
    "    hashtag_list = re.findall(hastags, text_string)\n",
    "    if len(hashtag_list) > 0:\n",
    "        return hashtag_list\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "extract_hashtags(\"This suppose to #return all #Hashtags in a string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d470ec-22ec-496b-8b33-650914d3f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mentions(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of mentions in input text\n",
    "    \"\"\"\n",
    "    mention = \"@(\\w+)\"\n",
    "    mention_list = re.findall(mention, text_string)\n",
    "    return mention_list\n",
    "\n",
    "\n",
    "extract_mentions('@Niloo try this function maybe @Nilo0 too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7f8e0-92a7-4f28-b63e-e9d394a76da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punctuations(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of hastags in input text\n",
    "    \"\"\"\n",
    "    puncts = [f'{p}' for p in string.punctuation] + ['...', '/n']\n",
    "    return [p for p in puncts if p in text_string]\n",
    "\n",
    "\n",
    "get_punctuations('this is stting!!!.....!?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677656c-3eaa-49ba-a36e-415c6ada3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclamaintion_mark_count(text_string):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        text_string\n",
    "    output:\n",
    "        count exclaimation marks in text_string\n",
    "    \"\"\"\n",
    "    return len([char for char in text_string if char == '!'])\n",
    "    \n",
    "    \n",
    "exclamaintion_mark_count('this is stting.!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02c4b1-95ce-4bd8-b7ba-a434dac3fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_mark_count(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text_string\n",
    "    output:\n",
    "        count question marks in text_string\n",
    "    \"\"\"\n",
    "    return len([char for char in text_string if char == '?'])\n",
    "\n",
    "\n",
    "question_mark_count('this is stting.!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcef7f7-3118-4827-87b7-df953c37a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppercase_words(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        counts number of all caps words\n",
    "    \"\"\"\n",
    "    word_list = text_string.split(\" \")\n",
    "    return [re.findall(r'\\b[A-Z]+(?:\\s+[A-Z]+)*\\b', word)[0] for word in word_list if re.findall(r'\\b[A-Z]+(?:\\s+[A-Z]+)*\\b', word)]\n",
    "\n",
    "\n",
    "uppercase_words('this counts Number of ALL CAPS words HERE Too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82bef0-bae0-4149-bc03-8521d2cf2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uppercase_words(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of hastags in input text\n",
    "    \"\"\"\n",
    "    return len(uppercase_words(text_string))\n",
    "\n",
    "\n",
    "count_uppercase_words('this counts Number of ALL CAPS words HERE Too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4466ef8-99b2-4857-b56c-9bd1bc860aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_case_pct(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text_string\n",
    "    output:\n",
    "        percentage of upper case letters of input string\n",
    "    \"\"\"\n",
    "    l = sum(1 for char in text_string if char!=\" \")\n",
    "    return round(sum(1 for char in text_string if char.isupper()) / l * 100)\n",
    "\n",
    "\n",
    "upper_case_pct('this counts Number of ALL CAPS words HERE Too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2223cce-b28c-4add-bb66-8065437645f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        clean string,\n",
    "            stopwords removed\n",
    "            punctuations removed\n",
    "            urls removed\n",
    "            convert to lower case characters\n",
    "    \"\"\"\n",
    "    text_string = text_string.replace('\\\\n', '')\n",
    "    stopword = stopwords.words('english')\n",
    "    punct = list(string.punctuation) + ['...']\n",
    "    \n",
    "    \n",
    "    text_string = tweet_urls_removed(text_string)\n",
    "    \n",
    "    sentence = re.sub(r'[^\\w\\s]', '', text_string)\n",
    "    sentence = [word for word in nltk.word_tokenize(sentence) if word not in punct and word not in stopword]\n",
    "    sentence = [Word(word).lemmatize().lower() for word in sentence]\n",
    "    \n",
    "    return \" \".join(sentence)\n",
    "\n",
    "\n",
    "clean_text(\"This, is #! CleaRly sth https://www.bbc.com/travel, HOW to have B@d words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fd11d-61cb-41e0-9631-acb4dc7cba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_polarity(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text_string\n",
    "    output:\n",
    "        semantic_score\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text_string)\n",
    "    score = blob.polarity\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score == 0:\n",
    "        return 'neutral'\n",
    "    elif score < 0:\n",
    "        return 'negative'\n",
    "    \n",
    "    \n",
    "get_semantic_polarity('This is What I try here, amazingly boring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5f376-fdb4-4b3d-88a2-f2b370db872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emoji(text_string):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        text_string\n",
    "    output:\n",
    "        extracted emojies\n",
    "    \"\"\"\n",
    "    emoji_summary = adv.extract_emoji([text_string])\n",
    "    return emoji_summary['emoji'][0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dca98-ebce-4c97-84fb-3e60d999baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emoji_group(text_string):\n",
    "    emoji_summary = adv.extract_emoji([text_string])\n",
    "    return emoji_summary['top_emoji_sub_groups']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048eb30-8be5-4678-9bb9-30bbcca530ce",
   "metadata": {},
   "source": [
    "# Reply / Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c74990-23c4-4152-9304-04445fb8262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(cid, df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    \n",
    "    \"\"\"\n",
    "    conversation = df.loc[df['referenced_tweets'].str.contains(f'{cid}')]\n",
    "    return conversation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c61cb-91e6-4c42-905a-4a7d4c4a9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_conversation(cid, df):\n",
    "    all_replies =  df.loc[df['conversation_id'] == cid]\n",
    "    return all_replies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc8065-8af3-4cbe-9fd6-e9c6f1d87ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replies_referenced_tweet_id(input_string):\n",
    "    return int(ast.literal_eval(input_string)[0]['id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8976ff-975a-4848-9395-d312a9514644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_reply_like_quote(df_row):\n",
    "    return int(df_row.retweet_count) + int(df_row.like_count) + int(df_row.quote_count) + int(df_row.all_replies_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b64088-2d2c-4769-b7d2-b3c8930f2822",
   "metadata": {},
   "source": [
    "# Update dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9581d-ff41-4df3-9e19-7507db0c2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hastags(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are lists, each item contains corresponding hashtags in tweets\n",
    "    \"\"\"\n",
    "    return df['text'].apply(lambda x: extract_hashtags(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dd5aa-ac17-4fe6-841c-a3930207abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_follower_count(df):\n",
    "    return df['author_id'].apply(lambda x: users.loc[users['id']==x]['followers_count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa96a6-cd7e-46e2-8318-41667c186b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uppercase_count(df):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are number of upper case words in corresponding tweets \n",
    "    \"\"\"\n",
    "    return df['text'].apply(lambda x: count_uppercase_words(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf56f8c-6e88-42e1-aa3b-c2d8972697ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clean_text(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are cleaned tweets\n",
    "    \"\"\"\n",
    "    return df['text'].apply(lambda x: clean_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a448b-8069-4f82-a73a-6fed29d5621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engagement_score(df):\n",
    "    try:\n",
    "        return df.apply(lambda x: x.total_raction/ (x.followers_count + 1), axis=1)\n",
    "    except: print('Error: Column \"total_raction\" does not exist')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c8d1a-6125-4d6b-aadb-25104c27ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uppercase(df):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        df: dataframe\n",
    "    output:\n",
    "        panda series, items are list of upper case words in tweets\n",
    "    \"\"\"\n",
    "    return df['text'].apply(lambda x: uppercase_words(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c80c64-028a-4453-9910-a30d36a0ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polarity(df):\n",
    "    try:\n",
    "        return df['clean_text'].apply(lambda x: get_semantic_polarity(x))\n",
    "    except:\n",
    "        return print('Error: Column \"clean_text\" does not exist')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260973b-5bb1-4f63-8859-09ca5a4437c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emoji_list(df):\n",
    "    return df['text'].apply(lambda x: extract_emoji(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18665ecc-6d92-4d40-aa72-e4d4e2047fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_reaction(df):\n",
    "    try:\n",
    "        return df.apply(lambda x: x.like_count + x.quote_count + x.retweet_count + x.all_reply_count, axis=1)\n",
    "    except: print('Error: Column \"all_reply_count\" does not exist')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b5cc8-23b1-4c06-828f-99d3c1eb6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emoji_group(df):\n",
    "    return df['text'].apply(lambda x: extract_emoji_group(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1834a2-02c7-4f58-ba9c-fb29e11c1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_all_reply(df, df_replies):\n",
    "    return df['conversation_id'].apply(lambda x: len(get_all_reply(x, df_replies)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
