{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b9ea0-69c7-434b-af5e-a084a57999aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "import ast\n",
    "import copy\n",
    "import glob\n",
    "import advertools as adv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 285\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from spacymoji import Emoji\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "from textblob import Word\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d023b88-3c3b-46df-a3d4-03fa2b149d81",
   "metadata": {},
   "source": [
    "# Load data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7506e-accd-4311-bf0a-cf788c426c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(paths, dtype):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        global paths to csv files\n",
    "    output:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "             \n",
    "    return pd.concat([pd.read_csv(path, dtype=dtype) for path in sorted(paths)], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab21b1-7e18-4433-8139-6e2e10273940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_feather(paths):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        global paths to feather files\n",
    "    output:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    return pd.concat([pd.read_feather(path) for path in sorted(paths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683aa03-db5d-4789-951f-411e4ad74928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, chunk_size = 10000): \n",
    "    list_of_chunks = []\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        list_of_chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return list_of_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25aeed2-d564-45ea-b63f-4fb7f35f5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_between(df, start, end):\n",
    "    \"\"\"\n",
    "    *** \n",
    "    input:\n",
    "        df: dataframe of tweets/replies/quotes\n",
    "        start: starting day : data frame, filter rows by column used_at_time value\n",
    "    \"\"\"\n",
    "    \n",
    "    df['date'] = df['created_at'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "\n",
    "    if start < end:\n",
    "        return df.loc[(df['date'] < end) & (df['date'] > start)]\n",
    "    else:\n",
    "        return df.loc[(df['date'] < end) | (df['date'] > start)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008f2e9-ecd0-4b6a-ac8a-325f838680fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_df(paths, pct, dtype):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        paths = global paths to csv files\n",
    "        pct = percentage of dataframe\n",
    "    output:\n",
    "        sample dataframe, for each csv file it takes pct% of the rows\n",
    "    \"\"\"\n",
    "    sample_df_list = []\n",
    "    for path in paths:\n",
    "        sample_df_list.append(pd.read_csv(path, dtype=dtype).sample(frac = pct))\n",
    "        \n",
    "    return pd.concat(sample_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2da38-c9ca-4dc8-92d6-8d221cf32ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_reply_quote(sample_df, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        sample_df: sample_tweet\n",
    "        df_conversation: replies or quotes dataframe\n",
    "    output:\n",
    "        dataframe, replies or quotes of the sample tweets\n",
    "    \"\"\"\n",
    "    conversation_list = []\n",
    "    print(len(sample_df))\n",
    "    for cnt, conv_id in enumerate(sample_df['conversation_id']):\n",
    "        conversation_list.append(get_conversation(conv_id, df_conversation))\n",
    "        if cnt % 1000 == 0:\n",
    "            print(cnt/len(sample_df))\n",
    "\n",
    "    return pd.concat(conversation_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f6eea-d1ee-49f3-83b2-b72b09e79512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_users(df_input):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_input: dataframe storing users information\n",
    "    output:\n",
    "        dataframe with not duplicates for user, ie. only has one row per users\n",
    "    \"\"\"          \n",
    "    return df_input.drop_duplicates(subset=\"id\", keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a7240-f381-4926-874e-1f6db7b68f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(cid, df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        cid: conversation id\n",
    "    output:\n",
    "        subdataframe, containing conversation of the specific tweet\n",
    "    \"\"\"\n",
    "\n",
    "    return df.loc[df['reference_tweet_id'] == cid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73428ae7-abbc-4b49-9787-2b68071a25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(ref_id, df_tweets):\n",
    "    dtemp = df_tweets.loc[df_tweets['conversation_id']==ref_id]\n",
    "    if len(dtemp) == 1:\n",
    "        return dtemp.iloc[0]['clean_text']\n",
    "    else:\n",
    "        []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f374206-52e4-4e22-a47b-967068dfb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_subset(df, conversation_list):\n",
    "    return df.loc[df['conversation_id'].isin(conversation_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d87b2e-78c6-413a-9b33-3333a5af616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_extended_features(df):\n",
    "#     \"\"\"\n",
    "#     input:\n",
    "#         df: dataframe of tweets, of sample of tweets, scored or unscored\n",
    "        \n",
    "#     output:\n",
    "#         dataframe containing extended features\n",
    "#     \"\"\" \n",
    "    \n",
    "#     conversation_list = list(df['conversation_id'])\n",
    "#     extended_tweets_cols = get_df_subset(EXTENDED_TWEETS, conversation_list)[EXTEXDED_COLS]\n",
    "    \n",
    "#     return pd.merge(df, extended_tweets_cols, on='conversation_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab6b9a35-f59b-451d-aa28-c46c0094abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extended_features(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets, of sample of tweets, scored or unscored\n",
    "        \n",
    "    output:\n",
    "        dataframe containing extended features\n",
    "    \"\"\" \n",
    "    \n",
    "    conversation_list = [int(elm) for elm in list(df['conversation_id'])]\n",
    "    extended_tweets_cols = get_df_subset(EXTENDED_TWEETS, conversation_list)[EXTEXDED_COLS]\n",
    "    \n",
    "    return pd.merge(df, extended_tweets_cols, on='conversation_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
