{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfc05d-8958-4593-9455-fc7a26765c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "import ast\n",
    "import copy\n",
    "import glob\n",
    "import advertools as adv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 285\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from spacymoji import Emoji\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "from textblob import Word\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "\n",
    "\n",
    "# stemmer = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79cd99d-c409-4397-88bb-e81fe5d65af0",
   "metadata": {},
   "source": [
    "# Data cleaning / Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe15bfc-0cab-4067-aaf9-34fcddeabb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        string\n",
    "    output: \n",
    "        urls list\n",
    "    \"\"\"\n",
    "\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text_string)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "\n",
    "extract_urls(\"this suppose to extract urls like https://www.bbc.com/travel/article/20220814-the-floating-homes-of-lake-titicaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573226a2-f7d1-41cb-8960-7160e465fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_urls_removed(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        string\n",
    "    output: \n",
    "        text_string urls removed\n",
    "    \"\"\"\n",
    "        \n",
    "    return re.sub(r'http\\S+', '', text_string)\n",
    "\n",
    "\n",
    "tweet_urls_removed(\"this suppose to extract urls like https://www.bbc.com/travel/article/20220814-the-floating-homes-of-lake-titicaca and retrun the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78ee90b-bda6-4cb0-a724-f778a7b291e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_hashtags(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of hastags found in input text\n",
    "    \"\"\"\n",
    "    hashtags = \"#(\\w+)\"\n",
    "    return re.findall(hashtags, text_string)\n",
    "    # hashtag_list = re.findall(hastags, text_string)\n",
    "    # if len(hashtag_list) > 0:\n",
    "    #     return hashtag_list\n",
    "    # else:\n",
    "    #     return None\n",
    "    \n",
    "    \n",
    "extract_hashtags(\"This suppose to return all  in a string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c97b2-d739-4cab-a121-a04661aa4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention_count(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of mentions in input text\n",
    "    \"\"\"\n",
    "    mention = \"@(\\w+)\"\n",
    "    mention_list = re.findall(mention, text_string)\n",
    "    return len(mention_list)\n",
    "\n",
    "\n",
    "mention_count('@Niloo try this function maybe @Nilo0 too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637651f-8ddc-4d4f-9dbb-3b6a41dee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_remove_mention(text_string):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        text_string\n",
    "    output:\n",
    "        text, mentions are removed from the text\n",
    "    \"\"\"\n",
    "    sentence = text_string.split()\n",
    "    mention = \"@(\\w+)\"\n",
    "    return re.sub(mention, '', text_string)\n",
    "\n",
    "\n",
    "\n",
    "tweet_remove_mention('@Niloo try this function maybe @Nilo0 too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0088fd-71f2-4d64-ba55-71cdf0cd02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punctuations(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of hastags in input text\n",
    "    \"\"\"\n",
    "    puncts = [f'{p}' for p in string.punctuation] + ['...', '/n']\n",
    "    return [p for p in puncts if p in text_string]\n",
    "\n",
    "\n",
    "get_punctuations('this is stting!!!.....!?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac612002-7339-4a6a-9086-0a3713cf431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclamaintion_mark_count(text_string):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        text_string\n",
    "    output:\n",
    "        count exclaimation marks in text_string\n",
    "    \"\"\"\n",
    "    return len([char for char in text_string if char == '!'])\n",
    "    \n",
    "    \n",
    "exclamaintion_mark_count('this is stting.!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb524d7-2ba9-4e42-840c-757a7e7acfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_mark_count(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text_string\n",
    "    output:\n",
    "        count question marks in text_string\n",
    "    \"\"\"\n",
    "    return len([char for char in text_string if char == '?'])\n",
    "\n",
    "\n",
    "question_mark_count('this is stting.!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37018d5a-54ec-4545-9672-30e39d69ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uppercase_words(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        counts number of all caps words\n",
    "    \"\"\"\n",
    "    word_list = text_string.split(\" \")\n",
    "    return [re.findall(r'\\b[A-Z]+(?:\\s+[A-Z]+)*\\b', word)[0] for word in word_list if re.findall(r'\\b[A-Z]+(?:\\s+[A-Z]+)*\\b', word)]\n",
    "\n",
    "\n",
    "uppercase_words('this counts Number of ALL CAPS words HERE Too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2c3e5-3f5b-42b8-ad80-2985a637884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_uppercase_words(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        list of hastags in input text\n",
    "    \"\"\"\n",
    "    return len(uppercase_words(text_string))\n",
    "\n",
    "\n",
    "count_uppercase_words('this counts Number of ALL CAPS words HERE Too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dcf7b-1863-4520-91ca-a44835209e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_case_pct(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text_string\n",
    "    output:\n",
    "        percentage of upper case letters of input string\n",
    "    \"\"\"\n",
    "    l = sum(1 for char in text_string if char!=\" \")\n",
    "    return round(sum(1 for char in text_string if char.isupper()) / l * 100)\n",
    "\n",
    "\n",
    "upper_case_pct('this counts Number of ALL CAPS words HERE Too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbc3aa-21af-4e54-9954-9ea004507971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_emojis(text_string):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        text_string\n",
    "    output:\n",
    "        integer, emoji count\n",
    "    \"\"\"\n",
    "    emoji_summary = adv.extract_emoji([text_string])\n",
    "    return emoji_summary['emoji_counts'][0]\n",
    "\n",
    "count_emojis('The Global Warming for ‚ù§Ô∏è‚Äçüî•‚ù§Ô∏è‚Äçüî• Warming  Fraud on society by Currupt Global Agencies. A multi part series of 3 minute explanations of the Net Zero Hoax.It stops ‚úãÔ∏è when we all say NO.@GBNEWS@PaulDuddridge @MarkSteynOnlinehttps://t.co/SFV2VLjypD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f9eb9-88b6-4f20-80b3-1fcb145aa36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text_string):\n",
    "    sentence = text_string.split(\" \")\n",
    "    return ' '.join([word for word in sentence if len(adv.extract_emoji([word])['emoji_flat_text']) == 0])\n",
    "\n",
    "remove_emoji(\"This, is #!  ‚ù§Ô∏è‚Äçüî•‚ù§Ô∏è‚Äçüî•  CleaRly sth https://www.bbc.com/travel, HOW to have B@d words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab0e61-1050-4742-a43a-acadc4410605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followers_count(author_id, df_users):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        author_id: self explanatory!\n",
    "        df_users, dataframe storing users information\n",
    "    output:\n",
    "        integer, count of followers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return df_users.loc[df_users['id']==author_id].iloc[0]['followers_count']\n",
    "    except:\n",
    "        return df_users['followers_count'].median()\n",
    "\n",
    "# get_followers_count(4704724720, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0024e-a794-4d31-8062-90b94fc9716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        clean string,\n",
    "            stopwords removed\n",
    "            punctuations removed\n",
    "            urls removed\n",
    "            convert to lower case characters\n",
    "    \"\"\"\n",
    "\n",
    "    stopword = stopwords.words('english')\n",
    "    punct = list(string.punctuation) + ['...']\n",
    "    \n",
    "    text_string1 = text_string.replace('\\\\n', '')\n",
    "    text_string2 = text_string1.replace('\\\\n', '')\n",
    "\n",
    "    \n",
    "    text_string3 = remove_emoji(text_string2)\n",
    "    text_string4 = tweet_urls_removed(text_string3)\n",
    "    text_string5 = tweet_remove_mention(text_string4)\n",
    "    \n",
    "    \n",
    "    sentence0 = re.sub(r'[^\\w\\s]', '', text_string5)\n",
    "    sentence1 = [word for word in nltk.word_tokenize(sentence0) if word not in punct and word not in stopword]\n",
    "    sentence2 = [Word(word).lemmatize().lower() for word in sentence1]\n",
    "    \n",
    "    return \" \".join(sentence2)\n",
    "\n",
    "\n",
    "clean_text(\"This, is #!  ‚ù§Ô∏è‚Äçüî•‚ù§Ô∏è‚Äçüî•  CleaRly sth https://www.bbc.com/travel, HOW to have B@d words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb8172-761d-46af-9842-2dfd37158d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(text_string):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        text_string\n",
    "    output:\n",
    "        id in following string \"[{???, 'id':123456789}]\" (not exactly the same of course)\n",
    "    \"\"\"\n",
    "    return int(json.loads(text_string.replace(\"'\", '\"'))[0]['id'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
