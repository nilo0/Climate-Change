{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756c8f2-c3dc-4130-8aeb-884314f32542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reference_id(df_input):\n",
    "    return df_input['referenced_tweets'].apply(lambda x: get_id(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15a4b8-89e5-468f-91a5-00009a387aad",
   "metadata": {},
   "source": [
    "# Update dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc75f3-fec3-480c-98b5-b0a9c99bd0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hashtags(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are lists, each item contains corresponding hashtags in tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: extract_hashtags(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12dd60b-c267-4dba-ba4f-71ee7738e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nbr_hashtags(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are number of hashtags in tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: len(extract_hashtags(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08803f1e-fd99-4d89-a48f-4f9597d09955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_exclamation_mark_count(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are number of exclamation marks in tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: exclamaintion_mark_count(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83c962-3fa8-4416-87eb-81115f95210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_question_mark_count(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are number of question marks in tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: question_mark_count(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac912f-dbfb-4932-8f7e-e595e89de92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_url_count(df): \n",
    "    \"\"\"\n",
    "    input: \n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are number of URLs in corresponding tweets \n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: len(extract_urls(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58806f75-6894-44f0-8387-6e9e3816340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_upper_case_pct(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        dataframe of tweet\n",
    "    output\n",
    "        panda series, items are percentage of uppercase characters in a tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: upper_case_pct(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02f9e3-fa07-412d-a942-9ff9789c067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uppercase_count(df):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are number of upper case words in corresponding tweets \n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: count_uppercase_words(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55944fb0-9b41-4b75-9901-c461435b5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mention_count(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: tweet's dataframe\n",
    "    output:\n",
    "        panda series, items are number of mentions in a tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: mention_count(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51113724-859d-4a1e-9b22-a7a17bfd4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emoji_count(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, counting number of emojis in each tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: count_emojis(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016382cf-c107-444b-b6c2-1f4383f7b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clean_text(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: dataframe of tweets\n",
    "    output:\n",
    "        panda series, items are cleaned tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['text'].apply(lambda x: clean_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f591708-6565-4748-831a-1565166d5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_followers_count(df, df_users):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: tweet's dataframe\n",
    "        df_users: dataframe, storiing users information\n",
    "    output:\n",
    "        panda series, each item is number of followers of tweeter users\n",
    "        if there was no information about number of followers, then assigns the median of followers count\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['author_id'].apply(lambda x: get_followers_count(x, df_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a091a3-5da6-4d22-93a9-8fe2da93981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engagement_score(df):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df: tweets/replies/quotes dataframe\n",
    "    output:\n",
    "        panda series, items are calculaed engagement scores\n",
    "    \"\"\"\n",
    "    \n",
    "    return (df['retweet_count'] + df['reply_count'] + df['like_count'] + df['quote_count'])/ (df['followers_count']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b18564-554e-4619-9c76-adb736729ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_score(df_input):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    df_input: tweets/replies/quotes dataframe\n",
    "    output:\n",
    "    panda series, items are calculaed sentiment scores\n",
    "    \"\"\"\n",
    "    return df_input['text'].apply(lambda x: sentiment_vader(sentiment_preprocessing(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fef2ab-9a34-4f25-b225-9e4a57e14b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_category(df_input):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    df_input: tweets/replies/quotes dataframe\n",
    "    output:\n",
    "    panda series, items are calculaed sentiment scores\n",
    "    \"\"\"\n",
    "    return df_input['text'].apply(lambda x: sentiment_vader_categorical(sentiment_preprocessing(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0465f00-5d6f-442c-8ade-3c83983d432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_average_conversation_sentiment(df_input, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_input: tweet's dataframe\n",
    "        df_conversation: rplies or quotes dataframe\n",
    "    output:\n",
    "        panda series, each item is the average score of conversation dataframe\n",
    "    \"\"\"\n",
    "    return df_input['conversation_id'].apply(lambda x: average_conversation_sentiment(get_conversation(x, df_conversation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7cb69-7d1a-4846-a04b-60873cfbb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variance_of_conversation_sentiment(df_input, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_input: tweet's dataframe\n",
    "        df_conversation: rplies or quotes dataframe\n",
    "    output:\n",
    "        panda series, each item is the average score of conversation dataframe\n",
    "    \"\"\"\n",
    "    return df_input['conversation_id'].apply(lambda x: variance_conversation_sentiment(get_conversation(x, df_conversation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648b2e1-c7c8-4c36-b602-4a869ee831cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pct_sentiment_category(df_input, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    df_input: tweets/replies/quotes dataframe\n",
    "    output:\n",
    "    panda series, items are calculaed sentiment scores\n",
    "    \"\"\"\n",
    "    return df_input['conversation_id'].apply(lambda x: get_sentiment_category_pct(x, df_input, df_conversation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdd4da-b44e-4339-af5c-28c760631c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tweet_to_conversation(df_tweet, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_tweet: dataframe of tweets\n",
    "        df_conversation: dataframe of replies/quotes\n",
    "    output:\n",
    "        panda series, items are reference tweet of a reply or quote\n",
    "    \"\"\"\n",
    "    return df_conversation['reference_tweet_id'].apply(lambda x: get_tweet(x, df_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b1aab-d669-464b-9960-c2f694316c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variance_of_conversation_semantic(df_input, df_conversation):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        df_input: tweet's dataframe\n",
    "        df_conversation: rplies or quotes dataframe\n",
    "    output:\n",
    "        panda series, each item is the average score of conversation's semantic scores dataframe\n",
    "    \"\"\"\n",
    "    return df_input['conversation_id'].apply(lambda x: variance_conversation_semantic(get_conversation(x, df_conversation)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
