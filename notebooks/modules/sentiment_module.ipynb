{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b332ecb-14de-40f7-9c5b-392ec88c53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./extract_info_clean_data_module.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ca2a7-2967-475e-8c55-cf3bf7f7f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "import ast\n",
    "import copy\n",
    "import glob\n",
    "import advertools as adv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 285\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from spacymoji import Emoji\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "from textblob import Word\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03a124-5ffb-44a7-80af-5a2061070044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_text(word_string):\n",
    "    if len(adv.extract_emoji([word_string])['emoji_flat_text']) == 0:\n",
    "        return word_string\n",
    "    else:\n",
    "        return ' '.join(adv.extract_emoji([word_string])['emoji_flat_text'])\n",
    "    \n",
    "# get_emoji_text('â¤ï¸â€ðŸ”¥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12390da9-0363-4c89-a2cc-949e4350a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emoji_with_text(input_string):\n",
    "    sentence = input_string.split(\" \")\n",
    "    return ' '.join([get_emoji_text(word) for word in sentence])\n",
    "    \n",
    "# replace_emoji_with_text('The Global Warming for â¤ï¸â€ðŸ”¥â¤ï¸â€ðŸ”¥ Warming  Fraud on society by Currupt Global Agencies. A multi part series of 3 minute explanations of the Net Zero Hoax.It stops âœ‹ï¸ when we all say NO.@GBNEWS@PaulDuddri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a354c2-54c8-4805-b36f-181a33eea695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_preprocessing(text_string):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        text string\n",
    "    output: \n",
    "        string where urls removed, \\n removed, mentions are removed\n",
    "    \"\"\"\n",
    "    text_string1 = text_string.replace('\\\\n', '')\n",
    "    text_string2 = text_string1.replace('\\n', '')\n",
    "    text_string3 = tweet_urls_removed(text_string2)\n",
    "    text_string4 = tweet_remove_mention(text_string3)\n",
    "    \n",
    "    return replace_emoji_with_text(text_string4)\n",
    "\n",
    "\n",
    "# s = \"\"\"The Global Warming for â¤ï¸â€ðŸ”¥â¤ï¸â€ðŸ”¥ Warming \n",
    "# Fraud on society by Currupt Global Agencies. \n",
    "# https://www.google.com/search?channel=fs&client=ubuntu&q=emojies\n",
    "# A multi part series of 3 minute explanations \\\\n of the Net Zero Hoax.It stops âœ‹ï¸ when we all say NO.@GBNEWS@PaulDuddri\"\"\"\n",
    "\n",
    "# sentiment_preprocessing(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d6ed2-2c24-40c1-b966-8f617261db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_vader(sentence):\n",
    "    \n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    negative = sentiment_dict['neg']\n",
    "    neutral = sentiment_dict['neu']\n",
    "    positive = sentiment_dict['pos']\n",
    "    compound = sentiment_dict['compound']\n",
    "\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        overall_sentiment = \"Positive\"\n",
    "\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        overall_sentiment = \"Negative\"\n",
    "\n",
    "    else :\n",
    "        overall_sentiment = \"Neutral\"\n",
    "  \n",
    "    return  compound # overall_sentiment, negative, neutral, positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62db76f-3ec1-4da5-a2b3-4fe3e6c559a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_vader('â¤ï¸â€ðŸ”¥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1157191-e55b-4afd-a035-191584c51b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_vader(sentiment_preprocessing('â¤ï¸â€ðŸ”¥'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
